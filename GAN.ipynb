{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Draw GAN\n",
    "\n",
    "A Generative Adversarial Network trained of the Google Quickdraw dataset found here: https://github.com/googlecreativelab/quickdraw-dataset#preprocessed-dataset\n",
    "\n",
    "Created in tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation,Reshape\n",
    "from keras.layers import BatchNormalization, Conv2D,Flatten, Conv2DTranspose, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_np,imshow,get_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path = 'full_numpy_bitmap_apple.npy'\n",
    "data = get_np(inp_path)\n",
    "img_w,img_h = data.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f98226c8ac8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD0xJREFUeJzt3XGsVOWZx/HfI4KJgFHkokgR9EY3ixrpOppNrBsWg9pKkEZqiomhiQgh1SyxJgtEUvxDg+uqS+LaBPVaNEoLsQomqCVGQ0mMYSBSbF0XQ6CyEBiixitRQO6zf9yDudU774wzZ+YMPN9PYmbmPOfc83j0d8/Mfc+c19xdAOI5regGABSD8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCOr0du5s9OjRPnHixHbuEghl9+7dOnTokNWzblPhN7ObJK2QNETS0+6+PLX+xIkTVS6Xm9klgIRSqVT3ug2/7TezIZL+W9KPJU2SNNvMJjX68wC0VzOf+a+R9JG773L3o5J+J+mWfNoC0GrNhH+cpI8HvN6bLfs7ZjbPzMpmVq5UKk3sDkCemgn/YH9U+M73g919pbuX3L3U1dXVxO4A5KmZ8O+VNH7A6x9I2tdcOwDapZnwb5F0iZldZGbDJP1c0vp82gLQag0P9bn712Z2t6Q31D/U1+Puf8mtM3SEjz/+OFnfuXNnsj516tQ820GOmhrnd/cNkjbk1AuANuLyXiAowg8ERfiBoAg/EBThB4Ii/EBQbf0+PzrPnj17kvXu7u5kfcyYMcl66jqBIUOGJLdFa3HmB4Ii/EBQhB8IivADQRF+ICjCDwTFUF9wDz74YLJ+wQUXJOu1vtLLcF7n4swPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzh/c9u3bk/WZM2cm62eccUae7aCNOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBNjfOb2W5JvZKOS/ra3Ut5NIX8VCqVZP348ePJ+ttvv52sHzt2LFkfOnRoso7i5HGRz7+6+6Ecfg6ANuJtPxBUs+F3SX80s61mNi+PhgC0R7Nv+691931mNkbSRjP7H3ffNHCF7JfCPEm68MILm9wdgLw0deZ3933Z40FJL0u6ZpB1Vrp7yd1LXV1dzewOQI4aDr+ZDTezkSeeS7pB0vt5NQagtZp523+epJfN7MTPedHdX8+lKwAt13D43X2XpCtz7AVVHD58OFlftmxZ1dpjjz2W3Lavr6+Rlr5R677+ixcvrlq76667ktuOHDmyoZ5QH4b6gKAIPxAU4QeCIvxAUIQfCIrwA0Fx6+42qDWctnbt2mR9wYIFyfqRI0eq1p544onkttOnT0/Wjx49mqyvWLEiWV+0aFFDNUmaP39+sn7fffcl6xMmTEjWo+PMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBmbu3bWelUsnL5XLb9tcp7r333mT98ccfT9bnzp2brD/yyCNVa2effXZy21br7e2tWnv66aeT2y5fvjxZP3jwYLJ+8803V6319PQktx0zZkyy3qlKpZLK5bLVsy5nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+HGzfvj1Znzx5crL+1FNPJeu1xvlPVbWm/37jjTeS9Xvuuadq7csvv0xuu3Xr1mR93LhxyXpRGOcHUBPhB4Ii/EBQhB8IivADQRF+ICjCDwRVc5zfzHokTZd00N0vz5aNkvR7SRMl7ZZ0m7t/WmtnJ/M4f+r+9ZMmTUpue/755yfrmzZtStZPO43f0Y34/PPPq9auvvrq5Lbd3d3J+oYNGxrqqdXyHuf/raSbvrVskaQ33f0SSW9mrwGcRGqG3903SfrkW4tvkbQqe75K0syc+wLQYo2+nzzP3fdLUvZ4ct7zCAis5R8mzWyemZXNrFypVFq9OwB1ajT8B8xsrCRlj1XvpOjuK9295O6lrq6uBncHIG+Nhn+9pDnZ8zmS1uXTDoB2qRl+M1st6R1J/2Bme83sTknLJU0zs52SpmWvAZxETq+1grvPrlK6PudeOtrDDz9ctbZnz57ktm+99Vayzjh+a5x11llVawsWLEhue//99+fdTsfh/zogKMIPBEX4gaAIPxAU4QeCIvxAUDWH+qJITSUtSQ888EDV2kMPPZTcdvz48Q31hNY5cuRIsj5ixIg2dVIczvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/JnNmzcn68ePH69au/POO/NuBy32xRdfJOuM8wM4ZRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM82fWrl2brF9xxRVVa+eee27e7aDFDh8+nKynbvt9quDMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB1RznN7MeSdMlHXT3y7NlyyTdJamSrbbE3Te0qsl2WLduXbK+cOHCNnWCdqhUKsn66NGj29RJceo58/9W0k2DLH/c3Sdn/5zUwQciqhl+d98k6ZM29AKgjZr5zH+3mf3ZzHrM7JzcOgLQFo2G/zeSuiVNlrRf0qPVVjSzeWZWNrNyrc9ZANqnofC7+wF3P+7ufZKeknRNYt2V7l5y91JXV1ejfQLIWUPhN7OxA17+VNL7+bQDoF3qGepbLWmKpNFmtlfSryVNMbPJklzSbknzW9gjgBaoGX53nz3I4mda0Euhent7k/UI476nmmPHjlWtvfLKK8ltly5dmnc7HYcr/ICgCD8QFOEHgiL8QFCEHwiK8ANBcetunLK2bdtWtVZriu5Zs2bl3U7H4cwPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzp8ZPnx4sv7ZZ5+1qRPU6+jRo8n63Llzq9ZSU65L0kUXXdRQTycTzvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/JkZM2Yk6y+99FLV2uLFi/NuB3VYsmRJsv7hhx9Wre3cuTO5rZk11NPJhDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRVc5zfzMZLek7S+ZL6JK109xVmNkrS7yVNlLRb0m3u/mnrWm2tO+64I1mfNm1a1dr27duT21555ZUN9RTd5s2bk/VHH300WX/22Wer1iZMmNBQT6eSes78X0v6lbv/o6R/lvRLM5skaZGkN939EklvZq8BnCRqht/d97v7tux5r6QPJI2TdIukVdlqqyTNbFWTAPL3vT7zm9lEST+U9K6k89x9v9T/C0LSmLybA9A6dYffzEZIeknSQnf//HtsN8/MymZWrlQqjfQIoAXqCr+ZDVV/8F9w9z9kiw+Y2disPlbSwcG2dfeV7l5y91JXV1cePQPIQc3wW//Xm56R9IG7PzagtF7SnOz5HEnr8m8PQKuYu6dXMPuRpD9J2qH+oT5JWqL+z/1rJF0o6W+Sfubun6R+VqlU8nK53GzPLdHX15esX3fddVVrn36aHuGsNRQ4dOjQZP1UVet26BdffHGyfv311yfra9asqVo7Vb+yWyqVVC6X6/qXqznO7+6bJVX7YemjD6BjcYUfEBThB4Ii/EBQhB8IivADQRF+IChu3Z057bT078Hnn3++au3SSy9Nbjtr1qxkffXq1cn6mWeemax3stT1E7fffnty22HDhiXrPT09yfqpOpafF878QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/x1Sn23/N13301uW+t757feemuy/tprryXrKbt27UrWhwwZkqw3e4vrJ598smrt9ddfT267ZcuWZH3kyJEN9YR+nPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+XNw1VVXJeuvvvpqsl5revBaY/VLly6tWnvxxReT29aycePGZH3UqFHJ+sKFC6vWUn1LtY8rmsOZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjnOb2bjJT0n6XxJfZJWuvsKM1sm6S5JlWzVJe6+oVWNnswuu+yyZP2rr75K1ru7u5P1c845p2qt1jUGL7zwQrI+bdq0ZL2WmTNnVq3VGudHa9Vzkc/Xkn7l7tvMbKSkrWZ24sqPx939P1vXHoBWqRl+d98vaX/2vNfMPpA0rtWNAWit7/WZ38wmSvqhpBP3rbrbzP5sZj1mNuh7TzObZ2ZlMytXKpXBVgFQgLrDb2YjJL0kaaG7fy7pN5K6JU1W/zuDRwfbzt1XunvJ3UtdXV05tAwgD3WF38yGqj/4L7j7HyTJ3Q+4+3F375P0lKRrWtcmgLzVDL/1T3X6jKQP3P2xAcvHDljtp5Lez789AK1Sz1/7r5V0h6QdZvZetmyJpNlmNlmSS9otaX5LOjwF1Pra644dO5L1d955J1mfOnVq1dqIESOS295www3J+vz56f+svb29yfqNN95YtXb66XyjvEj1/LV/s6TBJjpnTB84iXGFHxAU4QeCIvxAUIQfCIrwA0ERfiAoBlo7QK3LnmfMmNGyfQ8bNixZnzJlSsv2jWJx5geCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMzd27czs4qkPQMWjZZ0qG0NfD+d2lun9iXRW6Py7G2Cu9d1v7y2hv87Ozcru3upsAYSOrW3Tu1LordGFdUbb/uBoAg/EFTR4V9Z8P5TOrW3Tu1LordGFdJboZ/5ARSn6DM/gIIUEn4zu8nMPjSzj8xsURE9VGNmu81sh5m9Z2blgnvpMbODZvb+gGWjzGyjme3MHqtP0dv+3paZ2f9lx+49M/tJQb2NN7O3zOwDM/uLmf1btrzQY5foq5Dj1va3/WY2RNL/Spomaa+kLZJmu/tf29pIFWa2W1LJ3QsfEzazf5H0haTn3P3ybNl/SPrE3ZdnvzjPcfd/75Delkn6ouiZm7MJZcYOnFla0kxJv1CBxy7R120q4LgVcea/RtJH7r7L3Y9K+p2kWwroo+O5+yZJn3xr8S2SVmXPV6n/f562q9JbR3D3/e6+LXveK+nEzNKFHrtEX4UoIvzjJH084PVeddaU3y7pj2a21czmFd3MIM7Lpk0/MX36mIL7+baaMze307dmlu6YY9fIjNd5KyL8g83+00lDDte6+z9J+rGkX2Zvb1GfumZubpdBZpbuCI3OeJ23IsK/V9L4Aa9/IGlfAX0Myt33ZY8HJb2szpt9+MCJSVKzx4MF9/ONTpq5ebCZpdUBx66TZrwuIvxbJF1iZheZ2TBJP5e0voA+vsPMhmd/iJGZDZd0gzpv9uH1kuZkz+dIWldgL3+nU2ZurjaztAo+dp0243UhF/lkQxn/JWmIpB53f7DtTQzCzC5W/9le6r+z8YtF9mZmqyVNUf+3vg5I+rWkVyStkXShpL9J+pm7t/0Pb1V6m6L+t67fzNx84jN2m3v7kaQ/SdohqS9bvET9n68LO3aJvmargOPGFX5AUFzhBwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqP8HnfRf7CoqkagAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(data,1040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144722, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_builder(width = 64,p=0.4):\n",
    "    #Inputs\n",
    "    inputs=  Input((img_w,img_h,1))\n",
    "    \n",
    "    #Model Layers\n",
    "    conv1 = Conv2D(width*1,5,strides=2,padding='same',activation='relu')(inputs)\n",
    "    conv1 = Dropout(p)(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(width*2,5,strides=2,padding='same',activation='relu')(conv1)\n",
    "    conv2 = Dropout(p)(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(width*4,5,strides=2,padding='same',activation='relu')(conv2)\n",
    "    conv3 = Dropout(p)(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(width*8,5,strides=1,padding='same',activation='relu')(conv3)\n",
    "    conv4 = Dropout(p)(conv4)\n",
    "    conv4 = Flatten()(conv4)\n",
    "    \n",
    "    output = Dense(1,activation='sigmoid')(conv4)\n",
    "    \n",
    "    #Model Definiton\n",
    "    discriminator = Model(inputs,output)\n",
    "    discriminator.summary()\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vinayak/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/vinayak/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = discriminator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_builder(z_dims = 100,depth = 64,p = 0.4):\n",
    "    #inputs\n",
    "    inputs = Input((z_dims,))\n",
    "    \n",
    "    #Dense\n",
    "    dense1 = Dense(7*7*64)(inputs)\n",
    "    dense1 = BatchNormalization(momentum=0.9)(dense1)\n",
    "    dense1 = Activation('relu')(dense1)\n",
    "    \n",
    "    #Reshape to (7,7,64) tensor\n",
    "    reshaper = Reshape((7,7,64))(dense1)\n",
    "    reshaper = BatchNormalization()(reshaper)\n",
    "    reshaper = Dropout(p)(reshaper)\n",
    "    \n",
    "    #Deconvoliutions\n",
    "    deconv1 = UpSampling2D()(reshaper)\n",
    "    deconv1 = Conv2DTranspose(int(depth/2),kernel_size=5,padding='same')(deconv1)\n",
    "    deconv1 = BatchNormalization(momentum=0.9)(deconv1)\n",
    "    deconv1 = Activation('relu')(deconv1)\n",
    "    \n",
    "    deconv2 = UpSampling2D()(deconv1)\n",
    "    deconv2 = Conv2DTranspose(int(depth/4),kernel_size=5,padding='same')(deconv2)\n",
    "    deconv2 = BatchNormalization(momentum=0.9)(deconv2)\n",
    "    deconv2 = Activation('relu')(deconv2)\n",
    "    \n",
    "    deconv3 = Conv2DTranspose(int(depth/8),kernel_size=5,padding='same')(deconv2)\n",
    "    deconv3 = BatchNormalization(momentum=0.9)(deconv3)\n",
    "    deconv3 = Activation('relu')(deconv3)\n",
    "    \n",
    "    #Output\n",
    "    output = Conv2D(1,kernel_size=5,padding='same',activation='sigmoid')(deconv3)\n",
    "    model = Model(inputs,output)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 14, 14, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 8)         3208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 1)         201       \n",
      "=================================================================\n",
      "Total params: 397,217\n",
      "Trainable params: 390,705\n",
      "Non-trainable params: 6,512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_builder(z_dim=100):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_2 (Model)              (None, 28, 28, 1)         397217    \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 1)                 4311553   \n",
      "=================================================================\n",
      "Total params: 4,708,770\n",
      "Trainable params: 390,705\n",
      "Non-trainable params: 4,318,065\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial_model = adversarial_builder()\n",
    "adversarial_model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr=0.0004, decay=3e-8, clipvalue=1.0), \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=2000,batch=128):\n",
    "    \n",
    "    d_metrics = []\n",
    "    a_metrics = []\n",
    "    \n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        real_imgs = np.reshape(data[np.random.choice(data.shape[0],batch,replace=False)],(batch,28,28,1))\n",
    "        fake_imgs = generator.predict(np.random.uniform(-1.0, 1.0, size=[batch, 100]))\n",
    "        \n",
    "        x = np.concatenate((real_imgs,fake_imgs))\n",
    "        y = np.ones([2*batch,1])\n",
    "        y[batch:,:] = 0\n",
    "        \n",
    "        make_trainable(discriminator, True)\n",
    "        \n",
    "        d_metrics.append(discriminator.train_on_batch(x,y))\n",
    "        running_d_loss += d_metrics[-1][0]\n",
    "        running_d_acc += d_metrics[-1][1]\n",
    "        \n",
    "        make_trainable(discriminator, False)\n",
    "        \n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch, 100])\n",
    "        y = np.ones([batch,1])\n",
    "\n",
    "        a_metrics.append(adversarial_model.train_on_batch(noise,y)) \n",
    "        running_a_loss += a_metrics[-1][0]\n",
    "        running_a_acc += a_metrics[-1][1]\n",
    "        \n",
    "        if (i+1)%500 == 0:\n",
    "\n",
    "            print('Epoch #{}'.format(i+1))\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, running_d_loss/i, running_d_acc/i)\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, running_a_loss/i, running_a_acc/i)\n",
    "            print(log_mesg)\n",
    "            ###########\n",
    "            imshow(fake_imgs,5)\n",
    "            ##########\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            plt.figure(figsize=(5,5))\n",
    "\n",
    "            for k in range(gen_imgs.shape[0]):\n",
    "                plt.subplot(4, 4, k+1)\n",
    "                plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return a_metrics, d_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,28,28,1]\n\t [[{{node input_1}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7666e0bbb14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma_metrics_complete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_metrics_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-55c3988b2ccc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0ma_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversarial_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mrunning_a_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mrunning_a_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1186\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,28,28,1]\n\t [[{{node input_1}}]]"
     ]
    }
   ],
   "source": [
    "a_metrics_complete, d_metrics_complete = train(epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
